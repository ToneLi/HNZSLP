# LatticeTransformer-for-Zero-shot-learning
LatticeTransformer (word, bytes,..) for Zero shot learning

## (Task 1) Link prediction in Zero Shot Learning 

![1636244513(1)](https://user-images.githubusercontent.com/33856565/140627681-720760e2-29dc-40c4-b37f-8427366f9729.jpg)

On the top, ZSL-(KGE model) is the baseline is proposed in ZSGAN, such as ZSL-Tucker. (ZSGAN, OntoZSL) are two models from 2020, 2021. LENR is the model we proposed.


(--------NELL-ZS-----------Wiki-ZS---------)
| KGE  | Model     | MRR     | hits@10     |hits@5     |hits@1|MRR     |hits@10     |hits@5     |hits@1|
|---------- | ---------- | :-----------:  | :-----------: |:-----------: |:-----------: | :-----------: |:-----------: |:-----------: |:-----------: |
|TransE|  relation-surface BERT  |    |   |   | |-    |-  |-  |-
|Distmult|   relation-surface BERT  |  -  | - | - | -|  |  | |
|complex|   relation-surface BERT  |  -  | - | - | -|  |  | |
|Tucker  |    relation-surface BERT   | -    |-    |-  |-    |-  |-  |

